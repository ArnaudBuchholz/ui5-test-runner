{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udcda Documentation","text":""},{"location":"#overview","title":"\ud83c\udf41 Overview","text":"<p>A self-sufficient test runner for UI5 applications enabling parallel execution of tests.</p> <ul> <li> <p>Serve the application with <code>@ui5/cli</code>, then run :  <code>ui5-test-runner --port 8081 --url http://localhost:8080/test/testsuite.qunit.html</code>,</p> </li> <li> <p>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code>,</p> </li> <li> <p>Report is generated in the <code>report/</code> folder.</p> </li> </ul>"},{"location":"#presentations","title":"\ud83d\udcac Presentations","text":"<ul> <li>The initial concept (version 1 of <code>ui5-test-runner</code>) is explained in the article REserve - Testing UI5</li> <li>A different approach to UI5 tests execution, a live presentation from UI5Con'21</li> <li>ui5-test-runner v3, a live presentation from Devtoberfest</li> </ul>"},{"location":"#detailed-documentation","title":"\ud83d\udcd6 Detailed documentation","text":"<ul> <li>Command line usage</li> <li>Testing a \"remote\" application</li> <li>Coverage extraction</li> <li>Serving and testing the application (a.k.a. legacy mode)</li> <li>\ud83c\udd955.5.0 Batch mode</li> <li>Configuration file</li> <li>\u26a0\ufe0f Warnings</li> <li>Tips &amp; tricks</li> <li>How to demo</li> <li>Browser instantiation command</li> </ul> Automation Library Browser(s) Screenshots Scripts Traces puppeteer <code>chrome</code>, <code>firefox</code> \u2714\ufe0f \u2714\ufe0f1\ufe0f\u20e3 \u2714\ufe0f jsdom (none) \u274c \u2714\ufe0f \u2714\ufe0f playwright <code>chrome</code>, <code>firefox</code>, <code>webkit</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f selenium-webdriver <code>chrome</code>, <code>firefox</code>, <code>edge</code> \u2714\ufe0f \u2714\ufe0f1\ufe0f\u20e3 \u2714\ufe0f1\ufe0f\u20e3 webdriver.io <code>chrome</code>, <code>firefox</code> \u2714\ufe0f \u2714\ufe0f \u2714\ufe0f 1\ufe0f\u20e3 <code>chrome</code> <ul> <li>Mapping v1 settings to v2</li> </ul>"},{"location":"batch/","title":"Batch mode","text":""},{"location":"batch/#overview","title":"Overview","text":"<p>With version <code>5.5.0</code>, <code>ui5-test-runer</code> can execute more than one test project in a single run.</p> <p>This mode is activated when the <code>--batch</code> parameter is used :</p> <ul> <li>The initial command is called the main command</li> <li>Each executed test is named a batch item</li> </ul>"},{"location":"batch/#-batch-parameter","title":"<code>--batch</code> parameter","text":"<p>The <code>--batch</code> parameter accepts multiple values and supports three kind of parameters :</p> <ul> <li> <p>A folder : execution of <code>ui5-test-runner --batch &lt;folder&gt;</code> triggers the execution of <code>ui5-test-runner --cwd &lt;folder&gt;</code></p> </li> <li> <p>A configuration file (for instance: <code>ui5-test-runner.json</code>) : execution <code>ui5-test-runner --batch &lt;config.json&gt;</code> triggers the execution of <code>ui5-test-runner --config &lt;config.json&gt;</code></p> </li> <li> <p>A regular expression : if the value does not match any folder or file name, it is interpreted as a regular expression. Then, <code>ui5-test-runner</code> recursively scans the current working directory (<code>--cwd</code>) and when :</p> </li> <li> <p>a folder matches the regular expression : it adds <code>--batch &lt;folder&gt;</code></p> </li> <li> <p>a JSON file matches the regular expression : it adds <code>--batch &lt;filename&gt;</code></p> </li> </ul> <p>Once all the values are processed, <code>ui5-test-runner</code> starts the execution of all identified batch items in parallel (using the value of <code>--parallel</code>).</p>"},{"location":"batch/#execution","title":"Execution","text":"<p>Unlike the normal execution flow where the runner ensures :</p> <ul> <li>the parallel execution of several pages (QUnit or OPA),</li> <li>the generation of a single report.</li> </ul> <p>The batch mode implies the parallel execution of multiple batch items.</p> <p>\u26a0\ufe0f Assuming the defaut value for <code>--parallel</code> is 2, it means that 2 batch items are executed in parallel which, themselves, execute 2 test pages in parallel. That makes a total of 4 browsers executed in parallel.</p> <p>Each individual item execution generates its own report information (including coverage). Also, the main output is slightly different.</p> <pre><code>\u2714\ufe0f  Legacy JS Sample (JS_LEGACY)\n\u2714\ufe0f  JSDOM browser (JSDOM)\n\u2714\ufe0f  Legacy JS Sample with coverage (JS_LEGACY_COVERAGE)\n\u2714\ufe0f  Legacy JS Sample with junit XML report (JS_LEGACY_JUNIT_REPORT)\n[\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591\u2591]   0% Legacy JS Sample (no script injection) (JS_LEGACY_NO_SCRIPT)\n[-starting-]      Legacy JS Sample accessed using --url (JS_LEGACY_REMOTE)\n\u2839 Running batch items...\n</code></pre> <p>Example of batch output</p> <p>New parameters and behaviors are introduced to control the execution :</p> <ul> <li> <p><code>--report-dir</code>: when used in the main command, all batch items report folders are overridden to generate a folder under the main <code>--report-dir</code> :</p> </li> <li> <p><code>--batch-id</code>: if provided in a configuration file, this conditions the sub folder name used under the overridden <code>--report-dir</code> (otherwise a hash is computed based on the batch item folder / file path).</p> </li> <li> <p><code>--batch-label</code>: if provided in a configuration file, the label is used in the main command output (otherwise the folder / file path is being used).</p> </li> <li> <p><code>--if</code>: if provided in a configuration file, it conditions the execution of the batch item. The expression can test any environment variable (for instance: <code>--if \"ALL_TESTS === 'true'\"</code>) or use the Node.js' major version (<code>--if \"NODE_MAJOR_VERSION &gt;= 20\"</code>).</p> </li> <li> <p>Parameters flagged with \ud83d\udce1 are forwarded to the batch item execution.</p> </li> </ul>"},{"location":"browser/","title":"Browser instantiation command","text":""},{"location":"browser/#overview","title":"Overview","text":"<p><code>ui5-test-runner</code> can integrate different browsers to run the tests. In particular, it is delivered with the following implementations :</p> <ul> <li>puppeteer (chrome)</li> <li>playwright<ul> <li>chromium</li> <li>firefox</li> <li>webkit</li> </ul> </li> <li>selenium-webdriver<ul> <li>chrome</li> <li>firefox</li> <li>edge</li> </ul> </li> <li>jsdom experimental</li> </ul> <p>The integration consists of a browser instantiation process that is forked from <code>ui5-test-runner</code>, allowing the runner to capture the output and to do in-process communication.</p>"},{"location":"browser/#probing","title":"Probing","text":"<p>Before executing the tests, the runner queries the browser instantiation command to probe its capabilities.</p> <p>A JSON file is generated and its absolute path is submitted to the command as its only parameter.</p> <pre><code>{\n  \"capabilities\": \"~/report/probe/capabilities.json\",\n  \"url\": \"about:blank\",\n  \"dir\": \"~/report/probe\",\n  \"args\": []\n}\n</code></pre> <p>Probing request JSON file</p> <p>The probing request file is composed of the following properties :</p> <ul> <li><code>capabilities</code> : path to a result file the command must generate.</li> <li><code>url</code> : <code>\"about:blank\"</code></li> <li><code>dir</code> : the working folder allocated for the command.</li> <li><code>args</code> : the list of browser arguments specified when running <code>ui5-test-runner</code>.</li> </ul> <p>When <code>capabilities</code> contains a string, the command  must generate an answer JSON file in the given path. This file contains the list of capabilities of the browser.</p> <pre><code>{\n  \"modules\": [\n    \"puppeteer\"\n  ],\n  \"screenshot\": \".png\",\n  \"scripts\": true,\n  \"traces\": [\n    \"console\",\n    \"network\"\n  ]\n}\n</code></pre> <p>Capabilities answer JSON file</p> <p>The following members are considered :</p> <ul> <li><code>modules</code> : the list of NPM modules the command depends on, defaulted to <code>[]</code>. When modules are specified, the runner is responsible of finding the dependencies or installing them, when needed.</li> <li><code>parallel</code> : if the command supports parallel execution, defaulted to <code>true</code>.</li> <li><code>screenshot</code> : if the command supports screenshot, it contains the extension of the generated files, defaulted to <code>null</code> (screenshots are not supported).</li> <li><code>scripts</code> : if the command supports script injection before loading the page, defaulted to <code>false</code>.</li> <li><code>traces</code> : a list of keys representing the additional traces captured by the browser.</li> </ul> <p>NOTE : the command might request another probe with the dependent modules being resolved, this is done by returning the member <code>probe-with-modules</code> set to <code>true</code>.</p>"},{"location":"browser/#executing","title":"Executing","text":"<p>Once the capabilities are known, the command is executed to run the tests. A different request file is used :</p> <pre><code>{\n  \"capabilities\": {},\n  \"modules\": {\n    \"puppeteer\": \"~/node_modules/puppeteer\"\n  },\n  \"url\": \"https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/testsuite.qunit.html\",\n  \"retry\": 0,\n  \"scripts\": [\n    \"(function () { window['ui5-test-runner/base-host'] = 'http://localhost:8081' }())\",\n    \"...\"\n  ],\n  \"dir\": \"~/report/4_hRtpsQ_mU\",\n  \"args\": []\n}\n</code></pre> <p>Execution request JSON file</p> <p>The execution request file is composed of the following properties :</p> <ul> <li><code>capabilities</code> : the result of the probe operation. It can be used to store information that is available for execution.</li> <li><code>modules</code> : if the probe returned a list of modules, <code>ui5-test-runner</code> will ensure to find them either locally or globally. When not found, the runner installs the dependencies globally. Once all the dependencies are resolved, their respective path are given in this object (key is the module name, value is the path).</li> <li><code>url</code> : url of the test page to run.</li> <li><code>retry</code> : if the command (not the tests) failed for any reason, <code>ui5-test-runner</code> may try to execute again the same page. The retry count indicates the attempt count. You may use this information to secure the code when retry is not <code>0</code>.</li> <li><code>scripts</code> : the list of scripts to be injected before executing the page.</li> <li><code>dir</code>: the working folder allocated for the command.</li> <li><code>args</code>: the list of browser arguments specified when running <code>ui5-test-runner</code>.</li> </ul> <p>The command is expected to instantiate the browser and open the given url (after evaluating the scripts if any).</p>"},{"location":"browser/#screenshot","title":"Screenshot","text":"<p>During the tests execution, the runner may request the command to take a screenshot. This is done by exchanging in-process messages.</p> <p>The command must listen on the <code>'message'</code> event (using <code>process.on</code>) and check the <code>command</code> received on the property object. If the <code>command</code> is <code>screenshot</code>, the received object also contains a <code>filename</code> member to indicate to which path the screenshot must be generated.</p> <p>Once the screenshot is generated, the command must send back the same message (<code>process.send</code>).</p>"},{"location":"browser/#stopping","title":"Stopping","text":"<p>Once the tests are finished, or when the runner decides to stop the execution, an in-process message is sent to terminate the command.</p> <p>The command must listen on the <code>'message'</code> event (using <code>process.on</code>) and check the <code>command</code> property on the received object. If the <code>command</code> is <code>stop</code>, the command must terminate properly. The runner waits for some time (see <code>--browser-close-timeout</code>) before killing the command if still running.</p> <p>It is mandatory to ensure that the child process explicitly exits at some point (see this thread explaining the fork behavior with Node.js).</p>"},{"location":"browser/#testing","title":"Testing","text":"<p>To simplify the development of browser instantiation commands and / or check their compliance to the expectations, <code>ui5-test-runner</code> provides the <code>--capabilities</code> option to runs a battery of tests.</p>"},{"location":"configuration/","title":"Configuration file","text":"<p>It is also possible to preset parameters by creating a JSON file named <code>ui5-test-runner.json</code> where the runner is executed (i.e. <code>process.cwd()</code>).</p> <p>The property names match the option names, converted to lowerCamelCase. Files written for v1 may not by compatible with v2, check mapping.</p> <p>The file is applied before parsing the command line parameters, hence some parameters might be overridden.</p> <p>If you want the parameters to be forced (and not be overridden by the command line), prefix the parameter name with <code>!</code>.</p> <p>For example : <pre><code>{\n  \"!pageTimeout\": 900000,\n  \"globalTimeout\": 3600000,\n  \"failFast\": true\n}\n</code></pre></p> <p>The <code>pageTimeout</code> setting cannot be overridden by the command line parameters</p> <p>NOTE : Feature disabling parameters (for instance : <code>--no-screenshot</code>, <code>--no-coverage</code>) are not accepting any value and the configuration file value is ignored.</p> <p>The following properties are equivalent :</p> <pre><code>{\n  \"noCoverage\": true,\n  \"noCoverage\": false,\n  \"noCoverage\": null\n}\n</code></pre> <p>Properties are equivalent to <code>--no-coverage</code></p> <p>NOTE : The parameters accepting multiple values (denoted with ... as in <code>'--libs &lt;lib...&gt;</code>) may be converted to an array of values in the configuration file.</p> <p>For instance, <code>libs</code> parameter can be :</p> <pre><code>{\n  \"libs\": \"my/namespace/lib/=../my.namespace.lib/src/my/namespace/lib/\"\n}\n</code></pre> <p>Structure of the <code>libs</code> parameter when only one value is specified</p> <pre><code>{\n  \"libs\": [\n    \"my/namespace/lib/=../my.namespace.lib/src/my/namespace/lib/\",\n    \"my/namespace/lib2/=../my.namespace.lib2/src/my/namespace/lib2/\"\n  ]\n}\n</code></pre> <p>Structure of the <code>libs</code> parameter when multiple values are specified</p>"},{"location":"coverage/","title":"Coverage extraction","text":""},{"location":"coverage/#overview","title":"Overview","text":"<p>Tests ensure that the code behaves as expected. The code coverage checks which lines of code (function, branches...) are executed while running the tests.</p> <p>If the code coverage shows that only 10% of the code is executed during your tests it means that 90% of the code is either not tested or useless.</p> <p>NOTE : having 100% code coverage does not mean that the code is fully tested !</p> <p>For instance, considering the function to test :</p> <pre><code>function div (a, b) { return a / b; }\n</code></pre> <p>This assertion generates 100% code coverage :</p> <pre><code>assert.notStrictEqual(div(4,2), 0);\n</code></pre> <p>But, in reality, it says almost nothing on the tested code.</p>"},{"location":"coverage/#how-does-it-work","title":"How does it work ?","text":"<p>The following is a summary of the article REserve \u2014 Testing UI5 \u2014 Measuring code coverage.</p> <p>Three steps are required to measure code coverage : 1. Instrumentation of the code 2. Execution of the tests 3. Extraction and consolidation of code coverage</p> <p>The first step is realized with <code>nyc</code> which is a wrapper for <code>istanbul</code>. It rewrites the code in such a way that :</p> <ul> <li>The code behavior does not change</li> <li>While the code is executed, it keeps track of which functions, lines and conditions are evaluated.</li> </ul> <p><code>ui5-test-runner</code> takes care of the second step. Based on the mode and options, it will either substitute the source files with the instrumented ones or expect the source to provide coverage information (see below).</p> <p>While running, the runner extracts the code coverage information for each page (available within <code>window.top.__coverage__</code>) and stores it in the coverage temporary folder.</p> <p>When all the test pages are executed, the coverage report is generated using two commands :</p> <ul> <li><code>nyc merge</code> to merge the different coverage reports in a single one,</li> <li><code>nyc report</code> to generate the report.</li> </ul>"},{"location":"coverage/#nycrcjson","title":"<code>.nycrc.json</code>","text":"<p>Coverage settings are specified through a <code>.nycrc.json</code> file, available options are described here.</p> <p>The runner provides a minimal configuration file with : <pre><code>{\n  \"all\": true,\n  \"sourceMap\": false\n}\n</code></pre></p> <p>The <code>all</code> option, when set, significantly impacts the coverage report. It forces the runner to scan the project to discover all files :</p> <ul> <li>In <code>legacy</code> mode, the runner is responsible of instrumenting the sources.</li> <li>In <code>remote</code> mode, a scanner is required to discover and fetch instrumented files from the remote repository. A default scanner is provided for <code>@ui5/cli</code> served projects (<code>$/scan-ui5.js</code>).</li> </ul>"},{"location":"coverage/#legacy-mode","title":"Legacy mode","text":"<p>In this mode, source files are directly manipulated by <code>ui5-test-runner</code>.</p>"},{"location":"coverage/#remote-mode","title":"Remote mode","text":"<p>It is possible to extract code coverage using the <code>remote</code> mode.</p>"},{"location":"coverage/#javascript-ui5cli-projects-ui5middleware-code-coverage","title":"JavaScript <code>@ui5/cli</code> projects : <code>@ui5/middleware-code-coverage</code>","text":"<p>The <code>@ui5/middleware-code-coverage</code> middleware is capable of instrumenting the source files on the fly (by adding <code>?instrument=true</code> to the URL of the file).</p> <p>According to the documentation, the coverage information can be leveraged only from UI5 1.113 thanks to <code>qunit-coverage-istanbul.js</code> which adds the URL parameter dynamically.</p> <p><code>ui5-test-runner</code> reproduces the behavior by altering the URLs without <code>qunit-coverage-istanbul.js</code> making the coverage available for any version.</p> <p>Here is an example of <code>ui5.yaml</code> configuration file to include the middleware.</p> <pre><code>specVersion: '3.0'\nmetadata:\n  name: training-ui5con18-opa\ntype: application\nserver:\n  customMiddleware:\n  - name: \"@ui5/middleware-code-coverage\"\n    afterMiddleware: compression\n    configuration:\n      instrument:\n        produceSourceMap: true\n        coverageGlobalScope: \"window.top\"\n        coverageGlobalScopeFunc: false\n      excludePatterns:\n        - \"resources/\"\n</code></pre> <p>Implementation note : unlike the expected usage of the middleware, <code>ui5-test-runner</code> generates the coverage report. It forces the runner to download all the covered source files locally to ensure the report can be generated.</p>"},{"location":"coverage/#typescript-ui5cli-projects","title":"TypeScript <code>@ui5/cli</code> projects","text":""},{"location":"coverage/#tweaking-ui5-tooling-transpile-in-typescript-projects","title":"Tweaking <code>ui5-tooling-transpile</code> in TypeScript projects","text":"<p>The <code>ui5-tooling-transpile</code> middleware converts TypeScript into JavaScript while serving the application. Its configuration can be tweaked to also achieve instrumentation during this step.</p> <pre><code>specVersion: \"3.0\"\nserver:\n  customMiddleware:\n    - name: ui5-tooling-transpile-middleware\n      afterMiddleware: compression\n      configuration:\n        debug: true\n        babelConfig:\n          sourceMaps: true\n          ignore:\n          - \"**/*.d.ts\"\n          presets:\n          - - \"@babel/preset-env\"\n            - targets: defaults\n          - - transform-ui5\n            - overridesToOverride: true\n          - \"@babel/preset-typescript\"\n          plugins:\n          - istanbul\n</code></pre> <p>Also, add the <code>babel-plugin-istanbul</code> referenced in the last line to the project's dev dependencies: <pre><code>npm i --save-dev babel-plugin-istanbul\n</code></pre></p> <p>NOTE : The <code>overridesToOverride</code> is only needed in ui5 versions &lt; 1.112.x as mentioned in the transform-ui5 documentation.</p> <p>NOTE : You may consider tweaking in a distinct configuration file and use the <code>--config</code> option to run it.</p> <p>For instance : <code>ui5 serve --config ui5-coverage.yaml</code></p>"},{"location":"coverage/#excluding-test-code-from-coverage-reporting-in-typescript-projects","title":"Excluding test code from coverage reporting in TypeScript projects","text":"<p>To exclude the test files from coverage reporting, create a <code>.nycrc.json</code> file with the following content:</p> <pre><code>{\n  \"all\": true,\n  \"sourceMap\": false,\n  \"exclude\": [\n    \"**/test/**/*.ts\"\n  ]  \n}\n</code></pre>"},{"location":"coverage/#coverage-proxy-experimental","title":"coverage-proxy (experimental)","text":"<p>If the remote server does not provide instrumented source files, an experimental approach consists in using <code>ui5-test-runner</code> as a 'proxy' to get the files. It will instrument the sources on the fly.</p> <p>Example : <pre><code>ui5-test-runner --url https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/testsuite.qunit.html --coverage --coverage-proxy --coverage-proxy-include webapp/* --coverage-proxy-exclude webapp/test --disable-ui5\n</code></pre></p>"},{"location":"coverage/#aggregate-coverage-for-several-projects","title":"Aggregate coverage for several projects","text":"<p>It is possible to execute <code>ui5-test-runner</code> on several projects and aggregate all coverage results to generate a single report.</p> <p>There are several requirements :</p> <ul> <li> <p>Projects have a common base folder (referenced as <code>&lt;BASE_FOLDER&gt;</code>)</p> </li> <li> <p>Projects use the same language (JavaScript or TypeScript)</p> </li> <li> <p>Coverage extraction must be done the same way (legacy or remote)</p> </li> </ul>"},{"location":"coverage/#setup","title":"Setup","text":"<ul> <li> <p>A folder is needed to store the merged coverage, it is referenced as <code>&lt;MERGE_COVERAGE_FOLDER&gt;</code> (must be an absolute path). It must be cleared before the round of execution.</p> </li> <li> <p>A JSON configuration file is needed with the following content (replace <code>&lt;BASE_FOLDER&gt;</code> with the actual value), its path is  referenced as <code>&lt;NYC_CONFIG_FILE&gt;</code> (must be an absolute path).</p> </li> </ul> <pre><code>{\n    \"all\": true,\n    \"sourceMap\": false,\n    \"cwd\": \"&lt;BASE_FOLDER&gt;\"\n}\n</code></pre> <p>Content of the configuration file</p> <ul> <li><code>nyc</code> is installed and available when running <code>npx nyc --help</code></li> </ul>"},{"location":"coverage/#steps","title":"Steps","text":"<ul> <li>For each project (referenced as <code>&lt;PROJECT_NAME&gt;</code>) :</li> <li><code>ui5-test-runner</code> with coverage extraction</li> <li>By default, coverage information is stored in the project root under <code>.nyc_output\\merged\\coverage.json</code></li> <li> <p>after <code>ui5-test-runner</code> successful execution, copy <code>.nyc_output\\merged\\coverage.json</code> to <code>&lt;MERGE_COVERAGE_FOLDER&gt;/&lt;PROJECT_NAME&gt;.json</code></p> </li> <li> <p>Once all projects are executed and coverage files copied, execute <code>npx nyc merge &lt;MERGE_COVERAGE_FOLDER&gt; &lt;MERGE_COVERAGE_FOLDER&gt;/overall/coverage.json</code></p> </li> <li> <p>Then, execute <code>npx nyc report --reporter=lcov --reporter=cobertura --temp-dir &lt;MERGE_COVERAGE_FOLDER&gt;/overall --report-dir &lt;MERGE_COVERAGE_FOLDER&gt;/coverage --nycrc-path &lt;NYC_CONFIG_FILE&gt;</code></p> </li> </ul>"},{"location":"demo/","title":"\ud83d\udda5\ufe0f How to demo","text":"<p>\u24d8 The repository <code>training-ui5con18-opa</code> contains a sample UI5 application with qUnit and OPA tests. The project was modified to support many execution modes, including online, local with <code>@ui5/cli</code> or with a standalone web server (<code>reserve</code>).</p> <ul> <li>Clone the project <code>training-ui5con18-opa</code></li> <li>Change the current working directory to the cloned project and run <code>npm install</code></li> <li>Install <code>ui5-test-runner</code> globally with <code>npm install ui5-test-runner --global</code></li> </ul>"},{"location":"demo/#testing-with-karma","title":"Testing with Karma","text":"<p>\u24d8 <code>Karma</code> requires configuration files, the execution model is based on sequential execution of all tests in one window. Last but not least, it is deprecated.</p> <ul> <li>Run <code>npm run karma</code> to test with the karma runner</li> <li>Browser is visible</li> <li> <p>No coverage</p> </li> <li> <p>Run <code>npm run karma-ci</code> to test with the karma runner</p> </li> <li>Browser is hidden</li> <li> <p>Coverage is extracted</p> </li> <li> <p>Open <code>webapp\\test\\testsuite.qunit.html</code> which defines the test pages</p> </li> </ul>"},{"location":"demo/#ui5-test-runner","title":"ui5-test-runner","text":"<ul> <li>Run <code>ui5-test-runner --help</code>, the list of available options is displayed</li> <li>Open <code>https://arnaudbuchholz.github.io/ui5-test-runner/</code> to access complete documentation</li> </ul> <p>\u24d8 Some options are associated with an icon indicating in which mode it is supported :</p> <ul> <li>\ud83d\udcbb for legacy mode</li> <li>\ud83d\udd17 for remote mode</li> <li>\ud83e\uddea for capabilities mode</li> </ul> <p>These modes are detailed below.</p>"},{"location":"demo/#legacy-mode","title":"\ud83d\udcbb Legacy mode","text":"<p>\u24d8 The initial version of <code>ui5-test-runner</code> was designed to serve the application and run tes tests.</p>"},{"location":"demo/#serving-the-application","title":"Serving the application","text":""},{"location":"demo/#default-ui5-mapping","title":"Default UI5 mapping","text":"<ul> <li>Run <code>ui5-test-runner --port 8081 --serve-only</code></li> <li>Browse to <code>http://localhost:8081/</code>, the application starts</li> <li>In the application, use <code>[CTRL] + [SHIFT] + [P]</code> to see UI5 version</li> </ul>"},{"location":"demo/#changing-ui5-version","title":"Changing UI5 version","text":"<ul> <li>Browse to <code>https://ui5.sap.com/neo-app.json</code>, it enumerates the list of available versions</li> <li>Pick a version and run <code>ui5-test-runner --port 8081 --serve-only --ui5 https://ui5.sap.com/&lt;version&gt;</code></li> <li>For instance : <code>ui5-test-runner --port 8081 --serve-only --ui5 https://ui5.sap.com/1.118.1</code></li> <li>In a new browser window, open the debugger</li> <li>Disable the browser cache</li> <li>Browse to <code>http://localhost:8081/</code>, the application starts</li> <li>In the application, use <code>[CTRL] + [SHIFT] + [P]</code> to see UI5 version</li> </ul> <p>\u24d8 The switch works because the application does not use a fixed version of UI5. Instead, it loads a relative URL (<code>./resources/sap-ui-core.js</code>).</p> <ul> <li>In the debugger, go to the elements tab and expand the <code>&lt;head&gt;</code> tag</li> </ul> <p>\u26a0\ufe0f By default, <code>http://localhost:8081/resources/sap-ui-core.js</code> redirects to <code>https://ui5.sap.com/resources/sap-ui-core.js</code>. Depending on the network settings, this may slow down the tests. The <code>--cache</code> option enables the caching of UI5 files locally to speed up the tests.</p>"},{"location":"demo/#running-the-qunit-and-opa-tests","title":"Running the qUnit and OPA tests","text":"<ul> <li>Run <code>ui5-test-runner --port 8081 --serve-only</code></li> <li>Browse to <code>http://localhost:8081/test/testsuite.qunit.html</code></li> </ul>"},{"location":"demo/#testing-the-application","title":"Testing the application","text":"<ul> <li>Run <code>ui5-test-runner --port 8081</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> <li>Open <code>report/output.txt</code>, it summarizes the tests execution</li> <li>Open <code>report/report.html</code> in the browser, it details the tests execution</li> </ul> <p>\u24d8 The runner logs everything (depending on the instantiation command). Each test page is associated to a folder which name is shown in front of the page URL in the <code>output.txt</code>. For instance, <code>http://localhost:8081/test/unit/unitTests.qunit.html</code> is associated to the folder <code>le6KDh_XnDk</code>. The folder name is a hash based on the test page URL.</p> <ul> <li>Expand the folder associated to the unit tests (<code>le6KDh_XnDk</code>)</li> <li><code>done.png</code> : a screenshot captured after tests completion</li> <li><code>console.csv</code> : the browser console logs</li> <li><code>network.csv</code> : the browser network traces</li> <li><code>browser.json</code> : (internal) the browser instantiation file</li> <li><code>stdout.txt</code> : (internal) the driver standard output</li> <li><code>stderr.txt</code> : (internal) the driver error output</li> <li>Expand the folder associated to the <code>TodoListJourney</code> journey (<code>9NHJd7F6A5c</code>)</li> <li><code>&lt;testid&gt;-&lt;elapsed&gt;.png</code> : screenshots are captured for every assertion</li> </ul>"},{"location":"demo/#faster-testing","title":"\"Faster\" testing","text":"<p>\u24d8 Performance is impacted by a variety of factors, augmenting the number of workers does not guarantee faster execution.</p> <ul> <li>Run <code>ui5-test-runner --port 8081 --parallel 4</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> </ul>"},{"location":"demo/#custom-reporting","title":"Custom reporting","text":"<ul> <li>Run <code>ui5-test-runner --port 8081 --report-generator $/report.js $/junit-xml-report.js</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> <li>Open <code>report/junit.xml</code></li> </ul>"},{"location":"demo/#code-coverage","title":"Code coverage","text":"<ul> <li>Run <code>ui5-test-runner --port 8081 --coverage</code></li> <li>At the end of the execution, a textual report summarizes the coverage</li> <li>Open <code>coverage/lcov-report/index.html</code> in the browser</li> <li>Open <code>coverage/lcov.info</code> for raw coverage information</li> </ul> <p>\u24d8 Thresholds can be defined to fail the command line if the coverage is below the expected ratio, see <code>--coverage-check-branches</code>, <code>--coverage-check-functions</code>, <code>--coverage-check-lines</code>, <code>--coverage-check-statement</code>.</p> <p>\u24d8 Coverage instrumentation is based on <code>nyc</code>, the process can be customized with a configuration file and the option <code>--coverage-settings</code>.</p> <ul> <li>Run <code>ui5-test-runner --port 8081 --coverage --keep-alive</code></li> <li>Browse to <code>http://localhost:8081/component.js</code> to see instrumentated version</li> </ul>"},{"location":"demo/#remote-mode","title":"\ud83d\udd17 Remote mode","text":"<p>\u24d8 Starting with version 2, <code>ui5-test-runner</code> can execute UI5 tests even when the application is served externally.</p>"},{"location":"demo/#ui5-sample-applications","title":"UI5 sample applications","text":"<ul> <li>Browse to https://ui5.sap.com/#/demoapps</li> <li>Open the Browse Orders application</li> <li>The demo page also document tests links :</li> <li>Run Unit Tests</li> <li>Run Integration Tests</li> <li>Run <code>ui5-test-runner --url https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/unit/unitTests.qunit.html --url https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/integration/opaTests.qunit.html</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> </ul>"},{"location":"demo/#ui5-tooling","title":"UI5 tooling","text":"<p>\u24d8 The UI5 tooling is the recommended way to develop UI5 applications.</p> <ul> <li>Run <code>npm start</code></li> <li>Browse to <code>http://localhost:8080</code></li> <li>Navigate to <code>test/</code></li> <li>Run <code>ui5-test-runner --port 8081 --url http://localhost:8080/test/testsuite.qunit.html</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> </ul>"},{"location":"demo/#coverage-with-ui5middleware-code-coverage","title":"Coverage with <code>@ui5/middleware-code-coverage</code>","text":"<ul> <li>Run <code>npm start</code></li> <li>Open <code>ui5.yaml</code></li> <li>The <code>@ui5/middleware-code-coverage</code> can instrument files on the fly</li> <li>Open <code>http://localhost:8080/component.js</code> in a new browser window</li> <li>Open <code>http://localhost:8080/component.js?instrumented=true</code> in a new browser window</li> <li>Run <code>ui5-test-runner --port 8081 --url http://localhost:8080/test/testsuite.qunit.html --coverage</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> </ul>"},{"location":"demo/#any-server","title":"Any server","text":"<ul> <li>Run <code>npm run reserve</code></li> <li>Browse to <code>http://localhost:8080</code>, the application starts</li> <li>Run <code>ui5-test-runner --port 8081 --url http://localhost:8080/test/testsuite.qunit.html</code></li> <li>Follow the progress of the tests using <code>http://localhost:8081/_/progress.html</code></li> </ul>"},{"location":"demo/#coverage-proxy","title":"Coverage proxy","text":"<p>\u24d8 This feature is experimental.</p> <ul> <li>Run <code>npm run reserve</code></li> <li>Run <code>ui5-test-runner --port 8081 --url http://localhost:8080/test/testsuite.qunit.html --coverage --coverage-proxy --coverage-proxy-exclude test --disable-ui5</code></li> </ul>"},{"location":"demo/#capabilities-tester","title":"\ud83e\uddea Capabilities tester","text":"<ul> <li>Run <code>ui5-test-runner --capabilities</code></li> <li>Run <code>ui5-test-runner --capabilities --browser $/selenium-webdriver.js</code></li> </ul>"},{"location":"jsdom/","title":"jsdom","text":""},{"location":"jsdom/#capabilities","title":"Capabilities","text":"<code>--browser</code> <code>$/jsdom.js</code> Module jsdom Screenshots \u274c Scripts \u2714\ufe0f Traces <code>multiplex</code> 1\ufe0f\u20e3"},{"location":"jsdom/#options","title":"Options","text":"<pre><code>  --debug [flag]  Enable more traces (default: false)\n</code></pre>"},{"location":"jsdom/#implementation-notes","title":"Implementation notes","text":"<ul> <li> <p>\u26d4 This browser instantiation command is provided to demonstrate a different kind of integration. Yet, for performance and compatibility reasons (see below), it is not recommended to use it.</p> </li> <li> <p>\u26a0\ufe0f Despite being actively maintained, the <code>jsdom</code> project suffers from different implementation problems. <code>ui5-test-runner</code> implements a compatibility layer to compensate some of them (the ones that are detected during compatibility tests). It happens that UI5 and / or <code>jsdom</code> changes break this layer.</p> </li> <li> <p><code>jsdom</code> does not renders HTML pages, it cannot take screenshots</p> </li> <li> <p>Because no rendering is done, the <code>visible</code> OPA5 matcher is overridden to 'simulate' visibility testing. This may generate invalid results during OPA tests.</p> </li> <li> <p>1\ufe0f\u20e3 Because <code>jsdom</code> simulates HTML rendering inside Node.js, any exception immediately interrupts the process. This makes the usual console and network CSV writers unreliable. Instead, all the traces are sent through the standard output and the result <code>stdout.txt</code> is a mix of text and JSON output.</p> </li> </ul>"},{"location":"legacy/","title":"Serving and testing the application (a.k.a. legacy mode)","text":""},{"location":"legacy/#overview","title":"Overview","text":"<p><code>ui5-test-runner</code> can serve the application to test it. The application files are delivered through its inner web server.</p> <p>This mode offers unique capabilities :</p> <ul> <li>Selecting the UI5 version to use,</li> <li>Caching the UI5 resources to speed up the tests,</li> <li>Mapping of libraries,</li> <li>Measuring the code coverage.</li> </ul> <p>NOTE : <code>ui5-test-runner</code> can serve the application without testing it with the option <code>--serve-only</code>.</p>"},{"location":"legacy/#step-by-step","title":"Step by step","text":"<ul> <li>Clone the project you want to test</li> <li>If the project owns library dependencies (other than UI5), you must also clone them.   To check for project dependencies, you may look into :</li> <li><code>POM.xml</code> (for maven based builds) :   <pre><code>  &lt;dependencies&gt;\n      &lt;dependency&gt;\n          &lt;groupId&gt;com.sap.fiori&lt;/groupId&gt;\n          &lt;artifactId&gt;my.namespace.feature.project.lib&lt;/artifactId&gt;\n          &lt;version&gt;...&lt;/version&gt;\n      &lt;/dependency&gt;\n</code></pre></li> <li><code>manifest.json</code> file :   <code>json   {     \"sap.ui5\": {         \"dependencies\": {             \"libs\": {                 \"my.namespace.feature.lib\": {                     \"lazy\": true                 }</code></li> </ul> <p>The following assumes that the project and its dependencies are cloned in the same folder. You must handle the differences between the library project name / structure and the namespace it implements.</p> <ul> <li>In the project root folder, run the following command :</li> </ul> <p><code>ui5-test-runner --port 8081 --cache .ui5 --libs my/namespace/feature/lib/=../my.namespace.feature.project.lib/src/my/namespace/feature/lib/</code></p> <p>The list of options is available using <code>ui5-test-runner --help</code> but to explain the command : * <code>--port 8081</code> : uses the fixed http port <code>8081</code></p> <ul> <li> <p><code>--cache .ui5</code> : caches UI5 resources to boost loading of pages. It stores resources in a project folder named <code>.ui5</code> (you may use an absolute path if preferred).</p> </li> <li> <p><code>--libs my/namespace/feature/lib/=../my.namespace.feature.project.lib/src/my/namespace/feature/lib/</code> : maps the library path (access to URL <code>/resources/my/namespace/feature/lib/library.js</code> will be mapped to the file path <code>../my.namespace.feature.project.lib/src/my/namespace/feature/lib/library.js</code>)</p> </li> </ul> <p>You may also use : * <code>--ui5 https://ui5.sap.com/1.109.0/</code> : uses a specific version of UI5</p> <ul> <li> <p><code>--no-coverage</code> : ignores  code coverage measurement (if you don\u2019t need it, it speeds up a bit the startup)</p> </li> <li> <p><code>--browser-args --visible</code> : changes the browser spawning command line to make the browser windows visible (for puppeteer)</p> </li> <li> <p><code>--parallel 3</code> : increases the number of parallel execution (default is 2)</p> </li> </ul> <p>During the test executions (which can take some time) you can monitor the progress by opening : http://localhost:8081/_/progress.html</p> <p></p> <p>After the tests are executed :</p> <ul> <li>The command line output will provide a summary of executed pages and the corresponding failures :</li> </ul> <p></p> <ul> <li>The detailed test report is available in the report folder</li> </ul> <p></p> <ul> <li>The coverage report is available from http://localhost:8081/_/coverage/lcov-report/index.html</li> </ul> <p></p> <ul> <li> <p>Some folders are created to support execution, you may add them to your project <code>.gitignore</code> to exclude them from git :</p> </li> <li> <p><code>.nyc_output/</code> : contains coverage information</p> </li> <li> <p><code>report/</code> : contains test report (as well as screenshots and console log outputs)</p> </li> <li> <p><code>.ui5/</code> : contains cached UI5 resources</p> </li> <li> <p>These folder names can be changed through parameters</p> </li> </ul>"},{"location":"mapping_v1_v2/","title":"Mapping v1 settings to v2","text":"<ul> <li>v1 syntax is <code>-&lt;exampleOption&gt;:&lt;value&gt;</code>, configuration file keys are identical</li> <li>v2 syntax is <code>--&lt;example-option&gt;</code> <code>&lt;value&gt;</code>, configuration file keys are using lowerCamelCase (<code>exampleOption</code>)</li> </ul> <p>Options that must be updated are flagged with \u270d :</p> v1 v2 configuration file -cwd -c, --cwd cwd -port --port port -ui5 --ui5 ui5 -libs --libs libs -cache --cache cache -webapp --webapp webapp -testsuite --testsuite testsuite -pageFilter -pf, --page-filter pageFilter -pageParams -pp, --page-params pageParams -pageTimeout -pt, --page-timeout pageTimeout -globalTimeout -t, --global-timeout globalTimeout -failFast -f, --fail-fast failFast -keepAlive -k, --keep-alive keepAlive -watch -w, --watch watch -logServer -l, --log-server logServer -browser -b, --browser browser -browserRetry -br, --browser-retry browserRetry -noScreenshot --screenshot false, --no-screenshot noScreenshot -args -- \u270dbrowserArgs -parallel -p, --parallel parallel -tstReportDir -r, --report-dir \u270dreportDir -coverage --coverage, --no-coverage coverage -covSettings -cs, --coverage-settings \u270dcoverageSettings -covTempDir -ct, --coverage-temp-dir \u270dcoverageTempDir -covReportDir -cr, --coverage-report-dir \u270dcoverageReportDir -covReporters -cr, --coverage-reporters \u270dcoverageReporters"},{"location":"playwright/","title":"playwright","text":""},{"location":"playwright/#capabilities","title":"Capabilities","text":"<code>--browser</code> <code>$/playwright.js</code> Module playwright Screenshots \u2714\ufe0f <code>.png</code> Scripts \u2714\ufe0f Traces <code>console</code>, <code>network</code> <p>Browser selection is done by passing browser parameters. For instance :</p> <p><code>ui5-test-runner --browser $/playwright.js -- --browser chromium</code></p> <p>Supported browsers :</p> <ul> <li>chromium</li> <li>firefox</li> <li>webkit</li> </ul>"},{"location":"playwright/#options","title":"Options","text":"<pre><code>  -b, --browser &lt;name&gt;            Browser driver (default: \"chromium\")\n  --visible [flag]                Show the browser (default: false)\n  -w, --viewport-width &lt;width&gt;    Viewport width (default: 1920)\n  -h, --viewport-height &lt;height&gt;  Viewport height (default: 1080)\n  -l, --language &lt;lang...&gt;        Language(s) (see rfc5646) (default:\n                                  [\"en-US\"])\n  -u, --unsecure                  Disable security features (default: false)\n  -v, --video                     Record video (default: false)\n  -n, --har                       Record network activity with har file\n                                  (default: false)\n</code></pre>"},{"location":"playwright/#implementation-notes","title":"Implementation notes","text":"<ul> <li>If you use the video recording feature (<code>--video</code>), it is recommended to turn off the screenshots as it makes the screen flicker</li> <li>In the latest version, playwright requires an additional installation step (<code>npx playwright install</code>). The command executes it.</li> </ul>"},{"location":"puppeteer/","title":"puppeteer","text":""},{"location":"puppeteer/#capabilities","title":"Capabilities","text":"<code>--browser</code> <code>$/puppeteer.js</code> Module puppeteer Screenshots 1\ufe0f\u20e3 \u2714\ufe0f <code>.png</code> Scripts \u2714\ufe0f <code>chrome</code> \u274c <code>firefox</code> 2\ufe0f\u20e3 Traces <code>console</code>, <code>network</code>"},{"location":"puppeteer/#options","title":"Options","text":"<pre><code>  --visible [flag]                  Show the browser (default: false)\n  --firefox [flag]                  Use firefox instead of chrome (default:\n                                    false)\n  --binary &lt;binary&gt;                 Binary path\n  -w, --viewport-width &lt;width&gt;      Viewport width (default: 1920)\n  -h, --viewport-height &lt;height&gt;    Viewport height (default: 1080)\n  -l, --language &lt;lang...&gt;          Language(s) (see rfc5646) (default:\n                                    [\"en-US\"])\n  -u, --unsecure                    Disable security features (default: false)\n  --basic-auth-username &lt;username&gt;  Username for basic authentication (default:\n                                    \"\")\n  --basic-auth-password &lt;password&gt;  Password for basic authentication (default:\n                                    \"\")\n</code></pre> <p>For <code>chrome</code> browser, it is possible to provide extra parameters using <code>--</code> separator inside browser arguments.</p> <p>For instance :</p> <ul> <li><code>ui5-test-runner --url http://localhost:8080/testsuite.qunit.html -- --unsecure -- --disable-infobars</code></li> <li>or (equivalent) <code>ui5-test-runner --url http://localhost:8080/testsuite.qunit.html --browser-args --unsecure --browser-args -- --browser-args --disable-infobars</code></li> </ul>"},{"location":"puppeteer/#implementation-notes","title":"Implementation notes","text":"<ul> <li> <p>When facing the error <code>ERROR: Failed to set up Chrome r&lt;version&gt;!</code>, you might consider defining the environment variable <code>PUPPETEER_SKIP_DOWNLOAD=true</code>, see the corresponding puppeteer issue.</p> </li> <li> <p>To use with the puppeteer docker image, the runner must be configured to find the packages : <code>--alternate-npm-path /home/pptruser/node_modules</code>.</p> </li> <li> <p>1\ufe0f\u20e3 Screenshot feature is failing because of missing <code>structuredClone</code> API on Node.js 16. Since the problem is inside <code>puppeteer</code> (issue), the feature is turned off for this version.</p> </li> <li> <p>2\ufe0f\u20e3 <code>firefox</code> does not support scripting in <code>puppeteer</code>, see this issue.</p> </li> </ul>"},{"location":"selenium-webdriver/","title":"selenium-webdriver","text":""},{"location":"selenium-webdriver/#capabilities","title":"Capabilities","text":"<code>--browser</code> <code>$/selenium-webdriver.js</code> Module selenium-webdriver Screenshots \u2714\ufe0f <code>.png</code> Scripts \u2753 depends on the browser Traces \u2753 depends on the browser <p>Browser selection is done by passing browser parameters. For instance :</p> <p><code>ui5-test-runner --browser $/selenium-webdriver.js -- --browser firefox</code></p> <p>Supported browsers :</p> <ul> <li>chrome</li> <li>firefox</li> <li>edge</li> </ul>"},{"location":"selenium-webdriver/#options","title":"Options","text":"<pre><code>  -b, --browser &lt;name&gt;   Browser driver (default: \"chrome\")\n  --visible [flag]       Show the browser (default: false)\n  -s, --server &lt;server&gt;  Selenium server URL\n  --binary &lt;binary&gt;      Binary path\n  -u, --unsecure         Disable security features (default: false)\n</code></pre>"},{"location":"selenium-webdriver/#implementation-notes","title":"Implementation notes","text":"<p>Please check https://www.npmjs.com/package/selenium-webdriver#installation for installing browser driver.</p> <p>Unfortunately, the capabilities depend on the selected browser. Usually, <code>chrome</code> is the one with the most features.</p>"},{"location":"selenium-webdriver/#running-a-selenium-server-within-docker","title":"Running a selenium server within docker","text":"<p>To utilize Docker images for hosting the Selenium server, it is recommended to set up a host mapping to facilitate communication between the Docker container and the internal server of the UI5 test runner.</p> <p>For example, you can use the hostname <code>myhost</code>:</p> <ol> <li>Start the Docker container with the following command:</li> </ol> <pre><code>docker run -d -p 4444:4444 --add-host myhost:host-gateway --name selenium-chrome selenium/standalone-chrome:latest`\n</code></pre> <ol> <li>Execute the test runner using the <code>--localhost</code> option as shown below:</li> </ol> <pre><code>ui5-test-runner --localhost myhost --browser $/selenium-webdriver.js --browser chrome -s http://localhost:4444/wd/hub\n</code></pre>"},{"location":"testing/","title":"Testing a \"remote\" application","text":""},{"location":"testing/#overview","title":"Overview","text":"<p>With version 2, <code>ui5-test-runner</code> can test applications that are already served.</p> <p>This addresses the limits of the legacy mode :</p> <ul> <li>It is compatible with @ui5/cli,</li> <li>The application may have special requirements to be tested: this is externalized from the runner,</li> <li>More than one application can be tested at the same time.</li> </ul> <p>On the flip side, it does not enable these features :</p> <ul> <li>Selecting and caching the UI5 version,</li> <li>Measuring the code coverage.</li> </ul>"},{"location":"testing/#step-by-step","title":"Step by step","text":"<ul> <li>Start your application, let's assume that it is available from <code>https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/testsuite.qunit.html</code></li> <li>Run the following command :</li> </ul> <p><code>ui5-test-runner --port 8081 --url https://ui5.sap.com/test-resources/sap/m/demokit/orderbrowser/webapp/test/testsuite.qunit.html</code></p> <p>During the test executions (which can take some time) you can monitor the progress by opening : http://localhost:8081/_/progress.html</p> <p></p> <p>After the tests are executed :</p> <ul> <li>The command line output will provide a summary of executed pages and the corresponding failures :</li> </ul> <p></p> <ul> <li>The detailed test report is available in the report folder</li> </ul> <p></p> <ul> <li>The folder <code>report/</code> is created to support execution, you may add it to your project <code>.gitignore</code> to exclude it from git</li> </ul>"},{"location":"tipsNtricks/","title":"Tips & tricks","text":""},{"location":"tipsNtricks/#tips-tricks","title":"Tips &amp; tricks","text":""},{"location":"tipsNtricks/#troubleshooting","title":"\ud83d\udc1e Troubleshooting","text":"<p>When the tests are timing out or generate unexpected results, the following options might help to gather more information.</p> <ul> <li> <p>Lower the parallelism (<code>--parallel 1</code>) and focus on the failing test page (<code>--page-filter</code>).</p> </li> <li> <p>Use the browser option <code>--visible</code> (for instance: <code>ui5-test-runner -- --visible</code>) to display the browser while running the tests.</p> </li> <li> <p>When the browser is visible, use the option <code>--debug-keep-browser-open</code> to prevent the browser closing when the tests are completed: it gives access to the console log and the network traces.</p> </li> </ul>"},{"location":"tipsNtricks/#problems","title":"\u26d1 Problems","text":"<ul> <li> <p>Since version 17, node prefers IP v6 over IP v4. This may prevent the process to properly connect to <code>localhost</code>. Either prefer url with <code>http://127.0.0.1</code> or use the environment variable <code>NODE_OPTIONS=--dns-result-order=ipv4first</code>.</p> </li> <li> <p><code>ui5-test-runner</code> is regularly tested with the latest versions of <code>puppeteer</code>, <code>selenium-webdriver</code> and other packages. If you face troubles with one of these and you are not using the latest version (the runner will generate the PKGVRS warning), try upgrading.</p> </li> <li> <p>Because of the asynchronous nature of <code>sap.ui.define</code> and <code>sap.ui.require</code>, tests are usually loaded after the QUnit framework. It is recommended to execute <code>QUnit.config.autostart = false;</code> as soon as possible to ensure the test framework waits for the tests to be loaded and then call <code>QUnit.start();</code>. If not done properly, the <code>ui5-test-runner</code> is capable of running the tests and updates itself while the tests are being loaded. However, it might happen that the QUnit framework fails to handle the tests, which may also fail the runner.</p> </li> <li> <p>By default QUnit randomizes the unit tests order (not within OPA): use <code>QUnit.config.reorder = false;</code> to prevent this behavior. NOTE: this does not work if the <code>autostart</code> configuration is not done properly.</p> </li> <li> <p>For language testing, it is recommended to use <code>--page-params</code> with <code>sap-ui-language=DE</code> (for instance).</p> </li> </ul>"},{"location":"tipsNtricks/#performances","title":"\ud83d\udc5f Performances","text":"<ul> <li> <p>The runner takes a screenshot for every OPA assertion (<code>Opa5.assert.ok</code>) : disabling screenshots will speed up the tests. Yet, if a test fails, a screenshot is captured after the error (unless using <code>--screenshot-on-failure false</code>).</p> </li> <li> <p>To benefit from parallelization, use the option <code>--split-opa</code> (available from version <code>4.5.0</code>) : it automatically splits the OPA journeys into different test pages.</p> </li> </ul>"},{"location":"tipsNtricks/#ides","title":"\u270d IDEs","text":"<ul> <li><code>ui5-test-runner</code> runs in Business Application Studio provided the instance is created with the <code>Headless Testing Framework</code> extension. Then configure the runner to use the <code>webdriverio</code> browser combined with the <code>firefox</code> setting. For instance : <code>ui5-test-runner --browser $/webdriverio.js -- --browser firefox</code>.</li> </ul> <p>\u26a0\ufe0f As of March 2025, it is recommended to install <code>webdriverio@8</code> first as it works better than the latest one.</p>"},{"location":"usage/","title":"Command line usage","text":"<p>Use <code>ui5-test-runner --help</code> to display the list of options. The mapping between v1 options and v2 can be found here.</p> <p>Check additional information below.</p> Parameter Mode Description Default Value -V, --version output the version number --capabilities \ud83e\uddea Capabilities tester for browser -u, --url &lt;url...&gt; \ud83d\udd17 URL of the testsuite / page to test -c, --cwd &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea Set working directory <code>current working directory</code> --config &lt;json&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea Configuration file (relative to cwd) <code>\"ui5-test-runner.json\"</code> --port &lt;port&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea Port to use (0 to use any free one) <code>0</code> -r, --report-dir &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea Directory to output test reports (relative to cwd) <code>\"report\"</code> -pt, --page-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Limit the page execution time, fails the page if it takes longer than the timeout (0 means no timeout) <code>0</code> -f, --fail-fast [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Stop the execution after the first failing page <code>false</code> -fo, --fail-opa-fast [flag] \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Stop the OPA page execution after the first failing test <code>false</code> -k, --keep-alive [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea Keep the server alive <code>false</code> -l, --log-server [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Log inner server traces <code>false</code> -p, --parallel &lt;count&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea Number of parallel tests executions <code>2</code> -b, --browser &lt;command&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Browser instantiation command (relative to cwd or use $/ for provided ones) <code>\"$/puppeteer.js\"</code> --browser-args &lt;argument...&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Browser instantiation command parameters (use -- instead) --alternate-npm-path &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Alternate NPM path to look for packages (priority: local, alternate, global) --no-npm-install \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Prevent any NPM install (execution may fail if a dependency is missing) -bt, --browser-close-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Maximum waiting time for browser close <code>2000</code> -br, --browser-retry &lt;count&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Browser instantiation retries : if the command fails unexpectedly, it is re-executed (0 means no retry) <code>1</code> -oi, --output-interval &lt;interval&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Interval for reporting progress on non interactive output (CI/CD) (0 means no output) <code>30000</code> --offline [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Limit network usage (implies --no-npm-install) <code>false</code> --env &lt;name=value...&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Set environment variable --localhost &lt;host&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 [\ud83d\udca3 use carefully] Hostname for legacy URLs and callbacks <code>\"localhost\"</code> --ci [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 CI mode (no interactive output) <code>false</code> --deep-probe [flag] \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Deep probe (recursive, slower) <code>false</code> --probe-parallel &lt;count&gt; \ud83d\udcbb\ud83d\udd17\ud83e\uddea\ud83d\udce1 Number of parallel probes (0 to use --parallel) <code>0</code> --webapp &lt;path&gt; \ud83d\udcbb\ud83d\udd17 Base folder of the web application (relative to cwd) <code>\"webapp\"</code> -pf, --page-filter &lt;regexp&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Filter out pages not matching the regexp -pp, --page-params &lt;params&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Add parameters to page URL --page-close-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Maximum waiting time for page close <code>250</code> -t, --global-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Limit the pages execution time, fail the page if it takes longer than the timeout (0 means no timeout) <code>0</code> --screenshot [flag] \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Take screenshots during the tests execution (if supported by the browser) <code>true</code> --no-screenshot \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Disable screenshots during the tests execution (but not on failure, see --screenshot-on-failure) --screenshot-on-failure &lt;flag&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Take a screenshot when a test fails (even if --screenshot is false) <code>true</code> -st, --screenshot-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Maximum waiting time for browser screenshot <code>5000</code> -so, --split-opa [flag] \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Split OPA tests using QUnit modules <code>false</code> -rg, --report-generator &lt;path...&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Report generator paths (relative to cwd or use $/ for provided ones) <code>[\"$/report.js\"]</code> --progress-page &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Progress page path (relative to cwd or use $/ for provided ones) <code>\"$/report/default.html\"</code> --jest [flag] \ud83d\udcbb\ud83d\udd17\ud83d\udce1 [\u26a0\ufe0f experimental] Simulate jest environment --qunit-batch-size &lt;size&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 [\u26a0\ufe0f experimental] QUnit hooks batch size (disables screenshots) <code>0</code> --coverage [flag] \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Enable or disable code coverage --no-coverage \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Disable code coverage -cs, --coverage-settings &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Path to a custom .nycrc.json file providing settings for instrumentation (relative to cwd or use $/ for provided ones) <code>\"$/.nycrc.json\"</code> -ctd, --coverage-temp-dir &lt;path&gt; \ud83d\udcbb\ud83d\udd17 Directory to output raw coverage information to (relative to cwd) <code>\".nyc_output\"</code> -crd, --coverage-report-dir &lt;path&gt; \ud83d\udcbb\ud83d\udd17 Directory to store the coverage report files (relative to cwd) <code>\"coverage\"</code> -cr, --coverage-reporters &lt;reporter...&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 List of nyc reporters to use (text is always used) <code>[\"lcov\",\"cobertura\"]</code> -ccb, --coverage-check-branches &lt;percent&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 What % of branches must be covered <code>0</code> -ccf, --coverage-check-functions &lt;percent&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 What % of functions must be covered <code>0</code> -ccl, --coverage-check-lines &lt;percent&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 What % of lines must be covered <code>0</code> -ccs, --coverage-check-statements &lt;percent&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 What % of statements must be covered <code>0</code> -crs, --coverage-remote-scanner &lt;path&gt; \ud83d\udcbb\ud83d\udd17\ud83d\udce1 Scan for files when all coverage is requested <code>\"$/scan-ui5.js\"</code> -s, --serve-only [flag] \ud83d\udcbb\ud83d\udd17 Serve only <code>false</code> -w, --watch [flag] \ud83d\udcbb\ud83d\udd17 Monitor the webapp folder (or the one specified with --watch-folder) and re-execute tests on change <code>false</code> --watch-folder &lt;path&gt; \ud83d\udcbb\ud83d\udd17 Folder to monitor with watch (enables --watch if not specified) --start &lt;command&gt; \ud83d\udcbb\ud83d\udd17 Start command (might be an NPM script or a shell command) \u26a0\ufe0f the command is killed on tests completion --start-wait-url &lt;command&gt; \ud83d\udcbb\ud83d\udd17 URL to wait for (\ud83d\udd17 defaulted to first url) --start-wait-method &lt;method&gt; \ud83d\udcbb\ud83d\udd17 HTTP method to check the waited URL <code>\"GET\"</code> --start-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17 Maximum waiting time for the start command (based on when the first URL becomes available, also used for termination) <code>5000</code> --end &lt;script&gt; \ud83d\udcbb\ud83d\udd17 End script (will receive path to <code>job.js</code>) --end-timeout &lt;timeout&gt; \ud83d\udcbb\ud83d\udd17 Maximum waiting time for the end script <code>15000</code> --ui5 &lt;url&gt; \ud83d\udcbb\ud83d\udce1 UI5 url <code>\"https://ui5.sap.com\"</code> --disable-ui5 [flag] \ud83d\udcbb\ud83d\udce1 Disable UI5 mapping (also disable libs) <code>false</code> --libs &lt;lib...&gt; \ud83d\udcbb\ud83d\udce1 Library mapping (&lt;relative&gt;=&lt;path&gt; or &lt;path&gt;), use *=webapp/resources to map resources sub folder --mappings &lt;mapping...&gt; \ud83d\udcbb\ud83d\udce1 Custom mapping (&lt;match&gt;=&lt;file|url&gt;(&lt;config&gt;)) --cache &lt;path&gt; \ud83d\udcbb\ud83d\udce1 Cache UI5 resources locally in the given folder (empty to disable) --preload &lt;library...&gt; \ud83d\udcbb\ud83d\udce1 Preload UI5 libraries in the cache folder (only if --cache is used) --testsuite &lt;path&gt; \ud83d\udcbb Path of the testsuite file (relative to webapp, URL parameters are supported) <code>\"test/testsuite.qunit.html\"</code> -cp, --coverage-proxy [flag] \ud83d\udd17 [\u26a0\ufe0f experimental] use internal proxy to instrument remote files <code>false</code> -cpi, --coverage-proxy-include &lt;regexp&gt; \ud83d\udd17 [\u26a0\ufe0f experimental] urls to instrument for coverage <code>\".*\"</code> -cpe, --coverage-proxy-exclude &lt;regexp&gt; \ud83d\udd17 [\u26a0\ufe0f experimental] urls to ignore for coverage <code>\"/((test-)?resources\\|tests?)/\"</code> --batch &lt;specification...&gt; Batch specification --batch-id &lt;id&gt; Batch id (used for naming report folder) --batch-label &lt;label&gt; Batch label (used while reporting on execution) --if &lt;condition&gt; Condition runner execution -h, --help display help for command <p>Meaning of parameter values :</p> <ul> <li><code>[value]</code> : value is optional (usually boolean)</li> <li><code>&lt;value&gt;</code> : value is expected</li> <li><code>&lt;value...&gt;</code> : more than one value can be set</li> <li><code>&lt;timeout&gt;</code> : expressed either as a single numeric (ms) or with the following suffixes :</li> <li><code>&lt;number&gt;</code>ms</li> <li><code>&lt;number&gt;s</code> or <code>&lt;number&gt;sec</code> for seconds</li> <li><code>&lt;number&gt;m</code> or <code>&lt;number&gt;min</code> for minutes</li> </ul> <p>Options availability depends on the mode :</p> <ul> <li>\ud83d\udcbb when serving and testing (legacy mode)</li> <li>\ud83d\udd17 when testing remote pages (<code>--url</code>)</li> <li>\ud83e\uddea when testing browser capabilities  (<code>--capabilities</code>)</li> <li>\ud83d\udce1 when using batch mode, the parameter is transmitted from main command to batch item</li> </ul> <p>For browser arguments, it is recommended to use <code>--</code> and pass them after. In the configuration file, use <code>browserArgs</code>.</p>"},{"location":"v2/","title":"ui5-test-runner v2","text":""},{"location":"v2/#the-need-for-a-version-2","title":"The need for a version 2","text":"<p>When <code>ui5-test-runner</code> was first released, it was designed to solve a very specific problem. To run the unit &amp; integration tests of UI5 applications, the recommended solution was to use the <code>karma</code> runner.</p> <p>Since then, the <code>@ui5/cli</code> tools have evolved and UI5 now supports TypeScript. It means that the tool also had to evolve to be more compatible with the new possibilities.</p>"},{"location":"v2/#running-the-application","title":"Running the application","text":"<p>To work properly, the runner must serve the application.  The progress is measured by hooking the QUnit APIs and, through the hooks, AJAX callbacks are made to the inner server which then collects the successes and errors of the test. To enable the hook injections, the server deliver UI5 files and modify some of them (notably the qunit.js source files).</p> <p>With the progress of cli tools and the aim of UI5 to deliver more and more integrated tools, this approach was not sustainable. the runner must be able to run an already served application.</p>"},{"location":"v2/#reporting","title":"Reporting","text":"<p>One consistent feedback received on the first version of the runner was that reports were hard to capture. Indeed, the HTML page was doing AJAX requests to collect the different files composing the execution status. Once grabed and copied locally, the report could not be opened with file:// meaning it had to be served.</p>"},{"location":"v2/#debugging","title":"Debugging","text":"<p>Another drawback of version 1 is the lack of visibility over the execution process. One significant improvement was to add screenshots. At least, it was possible to \"see\" what happens during the tests. Yet, many other information can be captured such as the console logs or the network traces.</p>"},{"location":"v2/#more-browsers","title":"More browsers","text":"<p>From the beginning, the runner has been decoupled from the browser instantiation commands. A very basic command line interface was designed to delegate the browser manipulation to a separate code.</p> <p>However, the runner was assuming about the possibilities of what the browser was able to do.</p> <p>I quickly realized that, to extend the range of supported browsers, the runner should be notified of the </p>"},{"location":"v2/#version-2","title":"Version 2","text":""},{"location":"v2/#improved-reporting","title":"Improved reporting","text":""},{"location":"v2/#improved-tracing","title":"Improved tracing","text":""},{"location":"v2/#more-browsers_1","title":"More browsers","text":""},{"location":"warnings/","title":"\u26a0\ufe0f Warnings","text":"Code Reason PKGVRS The runner loads packages dynamically. It first searches for the ones that are local to the project (considering <code>--cwd</code>) and then the global ones. It is also possible to request an alternate path, see <code>--alternate-npm-path</code>. When the package is missing, the latest version is installed globally. Otherwise, the runner will compare the version of the package found with the latest in the NPM registry. If different, this warnings is shown. If problems occur while running the tests, consider upgrading the packages before submitting an issue. UNHAND In <code>legacy</code> mode, the runner acts as a web server for the application files. When a request cannot be served, the corresponding details are logged in the <code>unhandled.txt</code> report file. SKPNYC When <code>--url</code> is used, instrumentation is skipped because it is expected that the sources files are not reachable. See coverage for more details. COVMIS When <code>--coverage</code> is used but no coverage information is collected after a test completed: this may mean that the configuration is incomplete. See coverage for more details. COVORG When <code>--url</code> is used with <code>--coverage</code>, the runner must download (and / or scan) source files from the remote location. If the provided list of url does not have the same origin, only the first one is considered. COVALL When all coverage is requested (setting <code>all</code> in <code>.nycrc.json</code>), the runner tries to process all files either locally (<code>legacy</code>) or remotely (<code>remote</code>). When the runner cannot complete this task, this message indicates that the coverage report might miss some files. SKIPIF When the condition specified using <code>--if</code> returns a falsy value, the runner execution is skipped. BATCHF Invalid batch (<code>--batch</code>) specification, reason is specified in the trace. BATCHM Displayed when a batch item is executed, see Batch mode. STRTCT Failed to query and terminate all start command child processes, some may leak. HDLEAK Before terminating, the runner checks if any Node.js handle remains active that may prevent the shutdown. EBWARG Empty browser argument filtered out. BRWCPE Unexpected error issued by the browser child process."},{"location":"webdriverio/","title":"webdriver.io","text":""},{"location":"webdriverio/#capabilities","title":"Capabilities","text":"<code>--browser</code> <code>$/webdriverio.js</code> Module webdriverio Screenshots 2\ufe0f\u20e3 \u2714\ufe0f <code>.png</code> Scripts \u2714\ufe0f Traces 1\ufe0f\u20e3 \u274c <p>Browser selection is done by passing browser parameters. For instance :</p> <p><code>ui5-test-runner --browser $/webdriverio.js -- --browser firefox</code></p> <p>Supported browsers :</p> <ul> <li>chrome</li> <li>firefox</li> </ul>"},{"location":"webdriverio/#options","title":"Options","text":"<pre><code>  --visible [flag]                Show the browser (default: false)\n  -b, --browser &lt;name&gt;            Browser driver (default: \"chrome\")\n  --binary &lt;binary&gt;               Binary path\n  -w, --viewport-width &lt;width&gt;    Viewport width (default: 1920)\n  -h, --viewport-height &lt;height&gt;  Viewport height (default: 1080)\n  -l, --language &lt;lang...&gt;        Language(s) (see rfc5646) (default:\n                                  [\"en-US\"])\n  -u, --unsecure                  Disable security features (default: false)\n</code></pre> <p>For <code>chrome</code> browser, it is possible to provide extra parameters using <code>--</code> separator inside browser arguments.</p> <p>For instance :</p> <ul> <li><code>ui5-test-runner --url http://localhost:8080/testsuite.qunit.html --browser $/webdriverio.js -- --unsecure -- --disable-infobars</code></li> <li>or (equivalent) <code>ui5-test-runner --url http://localhost:8080/testsuite.qunit.html --browser $/webdriverio.js --browser-args --unsecure --browser-args -- --browser-args --disable-infobars</code></li> </ul>"},{"location":"webdriverio/#implementation-notes","title":"Implementation notes","text":"<ul> <li>1\ufe0f\u20e3 Traces are not yet implemented</li> <li>2\ufe0f\u20e3 Version <code>v9.6.x</code> of <code>webdriver.io</code> has problems with screenshot, see #117</li> </ul>"}]}